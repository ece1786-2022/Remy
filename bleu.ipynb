{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"code","source":["import nltk\n","nltk.download('punkt')\n","from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/Colab Notebooks/ece1786-project"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fV07OJupmfWC","executionInfo":{"status":"ok","timestamp":1668377755492,"user_tz":300,"elapsed":844,"user":{"displayName":"Yilun Li","userId":"14544822668767558115"}},"outputId":"426ec0d5-3e1c-4879-c341-13104e750fcb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/Colab Notebooks/ece1786-project\n"]}]},{"cell_type":"code","source":["import torch \n","import numpy as np\n","\n","from nltk.tokenize import sent_tokenize \n","\n","from pathlib import Path \n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import Dataset\n","from torch.utils.data.dataloader import DataLoader\n","from mingpt.bpe import BPETokenizer \n","from mingpt.utils import set_seed \n","from mingpt.model import GPT\n","import pandas as pd\n","set_seed(1234)"],"metadata":{"id":"wPo9HewGmxcw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class RecipeDataset(Dataset):\n","    def __init__(self,  truncation=-1):\n","        df = pd.read_pickle(\"cocktail_dataset.pkl\")  \n","        recipes = []\n","        for i in range(len(df.index)):\n","            recipe = \"RECIPE NAME\\n\" + df.loc[i, \"Name\"] + \" \\n\\nRECIPE INGREDIENTS\\n\"\n","            for ingredient in df.loc[i, \"Ingredients\"]:\n","                recipe += ingredient + \"\\n\"\n","            recipe += \"\\nRECIPE INSTRUCTIONS\\n\" \n","            for instruction in  df.loc[i, \"Instructions\"]:\n","                recipe += instruction + \"\\n\"\n","            recipes.append(recipe)\n","\n","        # Tokenize\n","        self.tokenizer = BPETokenizer()\n","        self.data = []  # List of 1-d pytorch tensor\n","        for sent in recipes:\n","            tokenized = self.tokenizer(sent).view(-1)  # pytorch tensor\n","            if truncation >= 0:\n","                self.data.append(tokenized[:truncation])\n","            else:\n","                self.data.append(tokenized)\n","\n","        # Count some items\n","        self.max_sentence_length = np.max([len(d) for d in self.data])\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def get_vocab_size(self):\n","        \"\"\"\n","        We have to set this to the max vocab size (i.e., that decided by the BPE tokenizer), \n","        but actually, only a small number of vocab is used, especially for the small text. \n","        \"\"\"\n","        return 50257\n","\n","    def __getitem__(self, idx):\n","        \"\"\"\n","        The output should be a tuple x and y, both as pytorch tensors.\n","        Please refer to the `run()` method in the mingpt/trainer.py script for \n","        how the x and y are going to be used.\n","        \"\"\"\n","        x = self.data[idx][:-1]\n","        y = self.data[idx][1:]\n","        return (x, y)\n","\n","    def get_block_size(self):\n","        \"\"\"\n","        block_size is the size at which lines are truncated to ensure they are equal-length.\n","        \"\"\"\n","        return self.max_sentence_length\n","    \n","\n","dataset = RecipeDataset(truncation=512) #use this for long"],"metadata":{"id":"miOwyY-2m0T9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device('cpu')"],"metadata":{"id":"5Pz-ODCYEQvd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_config = GPT.get_default_config()\n","model_config.model_type = 'gpt-nano'\n","model_config.vocab_size = dataset.get_vocab_size()\n","model_config.block_size = dataset.get_block_size()\n","model_config.n_classification_class = 2\n","model = GPT(model_config)\n","model.load_state_dict(torch.load(\"recipe_baseline.pt\", map_location=torch.device('cpu')))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V2WjOH4W2A7y","executionInfo":{"status":"ok","timestamp":1668377822393,"user_tz":300,"elapsed":263,"user":{"displayName":"Yilun Li","userId":"14544822668767558115"}},"outputId":"1033402b-0d34-4643-e93c-379032f5f895"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["number of parameters: 2.52M\n"]},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["!pip install evaluate"],"metadata":{"id":"38ioZ7Wlq4WI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import evaluate"],"metadata":{"id":"QxeQWdheq9PL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_propmts(filename):\n","  df = pd.read_pickle(filename)\n","  answers = []\n","  prompts = []\n","  for i in range(len(df.index)):\n","    recipe = \"RECIPE NAME\\n\" + df.loc[i, \"Name\"] + \" \\n\\nRECIPE INGREDIENTS\\n\"\n","    prompts.append(recipe)\n","    for ingredient in df.loc[i, \"Ingredients\"]:\n","      recipe += ingredient + \"\\n\"\n","    recipe += \"\\nRECIPE INSTRUCTIONS\\n\" \n","    for instruction in  df.loc[i, \"Instructions\"]:\n","      recipe += instruction + \"\\n\"\n","    answers.append([recipe])\n","  return answers, prompts"],"metadata":{"id":"WBCB9NK4bWyn","executionInfo":{"status":"ok","timestamp":1668385043909,"user_tz":300,"elapsed":116,"user":{"displayName":"Yilun Li","userId":"14544822668767558115"}}},"execution_count":76,"outputs":[]},{"cell_type":"code","source":["answers, prompts = create_propmts(\"cocktail_dataset.pkl\")"],"metadata":{"id":"QA_eCuP9c7wE","executionInfo":{"status":"ok","timestamp":1668385063312,"user_tz":300,"elapsed":112,"user":{"displayName":"Yilun Li","userId":"14544822668767558115"}}},"execution_count":77,"outputs":[]},{"cell_type":"code","source":["def bleu_score(answers, prompts):\n","  attempts = []\n","  for i in range(len(answers)):\n","    encoded_prompt = dataset.tokenizer(prompts[i]).to(device)\n","    generated_sequence = model.generate(encoded_prompt, device, temperature=0.5, max_new_tokens=100, do_sample=True)\n","    attempts.append(dataset.tokenizer.decode(generated_sequence[0].squeeze()))\n","  bleu = evaluate.load(\"bleu\")\n","  results = bleu.compute(predictions=attempts, references=answers)\n","  return results\n"],"metadata":{"id":"uccopdsvg6TH","executionInfo":{"status":"ok","timestamp":1668385924183,"user_tz":300,"elapsed":119,"user":{"displayName":"Yilun Li","userId":"14544822668767558115"}}},"execution_count":79,"outputs":[]},{"cell_type":"code","source":["bleu_score(answers, prompts)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gOSuqkR3jO3h","executionInfo":{"status":"ok","timestamp":1668386549100,"user_tz":300,"elapsed":614414,"user":{"displayName":"Yilun Li","userId":"14544822668767558115"}},"outputId":"e83202ad-258a-464a-d462-893afc78f49e"},"execution_count":80,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'bleu': 0.19416963417840508,\n"," 'precisions': [0.5756777276584342,\n","  0.3501765824504211,\n","  0.23584775721959506,\n","  0.16488172844105048],\n"," 'brevity_penalty': 0.652549723552336,\n"," 'length_ratio': 0.7008357069078844,\n"," 'translation_length': 22391,\n"," 'reference_length': 31949}"]},"metadata":{},"execution_count":80}]}]}